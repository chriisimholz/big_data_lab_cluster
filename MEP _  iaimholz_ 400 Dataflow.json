{"paragraphs":[{"text":"%md\n# Dataflow","user":"bd01","dateUpdated":"2021-05-17T20:28:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Dataflow</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1620063675955_-319698746","id":"20210127-071031_1944670894","dateCreated":"2021-05-03T17:41:15+0000","dateStarted":"2021-05-17T20:28:15+0000","dateFinished":"2021-05-17T20:28:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4617"},{"text":"%md\n\n## Speicherung CSV Files\n\n![alt text](https://raw.githubusercontent.com/chriisimholz/bdlc-fs21/main/Dataflow%20einfacher%20Prozess%20BDLC%2023%20v5.jpg)\n","user":"bd01","dateUpdated":"2021-05-30T13:59:28+0000","config":{"colWidth":8,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Speicherung CSV Files</h2>\n<p><img src=\"https://raw.githubusercontent.com/chriisimholz/bdlc-fs21/main/Dataflow%20einfacher%20Prozess%20BDLC%2023%20v5.jpg\" alt=\"alt text\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1620222018986_-613229390","id":"20210505-134018_960155071","dateCreated":"2021-05-05T13:40:18+0000","dateStarted":"2021-05-30T13:59:28+0000","dateFinished":"2021-05-30T13:59:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4618"},{"text":"%md\n### Speicherung der CSV Files\n#### Beschreibung: \n\nDie Daten werden per API mittels Curl bezogen und auf dem Gateway zwischengespeichert. Anschliessend werden die Files auf dem HDFS gespeichert. Durch MapReduce und HDFS werden die Daten auf verschiedenen Datanodes in diesem Fall in 8 MB grossen Blöcken gespeichert. Das Hadoop Framework ermöglicht eine flexible Skalierung des Clusters.","user":"bd01","dateUpdated":"2021-05-30T14:00:25+0000","config":{"colWidth":4,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Speicherung der CSV Files</h3>\n<h4>Beschreibung:</h4>\n<p>Die Daten werden per API mittels Curl bezogen und auf dem Gateway zwischengespeichert. Anschliessend werden die Files auf dem HDFS gespeichert. Durch MapReduce und HDFS werden die Daten auf verschiedenen Datanodes in diesem Fall in 8 MB grossen Blöcken gespeichert. Das Hadoop Framework ermöglicht eine flexible Skalierung des Clusters.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1621278878636_-238448600","id":"20210517-191438_111010645","dateCreated":"2021-05-17T19:14:38+0000","dateStarted":"2021-05-30T14:00:25+0000","dateFinished":"2021-05-30T14:00:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4619"},{"text":"%md\n\n## Bezug der Daten\n\n![alt text](https://raw.githubusercontent.com/chriisimholz/bdlc-fs21/main/Dataflow%20bezug%20Prozess%20BDLC%2023.jpg)","user":"bd01","dateUpdated":"2021-05-22T09:13:59+0000","config":{"colWidth":8,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Bezug der Daten</h2>\n<p><img src=\"https://raw.githubusercontent.com/chriisimholz/bdlc-fs21/main/Dataflow%20bezug%20Prozess%20BDLC%2023.jpg\" alt=\"alt text\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1621283296674_-1354969343","id":"20210517-202816_1743957945","dateCreated":"2021-05-17T20:28:16+0000","dateStarted":"2021-05-22T09:13:47+0000","dateFinished":"2021-05-22T09:13:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4620"},{"text":"%md\n### Bezug der Daten\n#### Beschreibung: \n\nDie Daten werden für eine Auswertung auf dem Zepplin Notebook gebraucht und dafür beim HDFS bezogen. Nach dem Request liefert der Namenode die Speicherorte der Blocks. Diese Blocks werden auf den Datanodes abgerufen und aggregiert. Danach können die Daten auf dem Notebook dargestellt werden. \n\n","user":"bd01","dateUpdated":"2021-05-22T09:22:24+0000","config":{"colWidth":4,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Bezug der Daten</h3>\n<h4>Beschreibung:</h4>\n<p>Die Daten werden für eine Auswertung auf dem Zepplin Notebook gebraucht und dafür beim HDFS bezogen. Nach dem Request liefert der Namenode die Speicherorte der Blocks. Diese Blocks werden auf den Datanodes abgerufen und aggregiert. Danach können die Daten auf dem Notebook dargestellt werden.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1621674733107_2042903338","id":"20210522-091213_759446428","dateCreated":"2021-05-22T09:12:13+0000","dateStarted":"2021-05-22T09:22:22+0000","dateFinished":"2021-05-22T09:22:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4621"},{"text":"%md\n","user":"bd01","dateUpdated":"2021-05-22T09:20:51+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1621675251897_1178749118","id":"20210522-092051_1885537567","dateCreated":"2021-05-22T09:20:51+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4622"}],"name":"MEP /  iaimholz/ 400 Dataflow","id":"2G5FFXJTN","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}